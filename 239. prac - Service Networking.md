### 239. prac - Service Networking
- 컨트롤 플레인의 IP 주소 범위 확인
```bash
controlplane ~ ➜  ip -4 a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
3: eth0@if23177: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1410 qdisc noqueue state UP group default  link-netnsid 0
    inet 192.168.59.170/32 scope global eth0
       valid_lft forever preferred_lft forever
4: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1360 qdisc noqueue state UNKNOWN group default 
    inet 172.17.0.0/32 scope global flannel.1
       valid_lft forever preferred_lft forever
```

- 클러스터의 `Pod-network-cidr` 확인
```bash
controlplane ~ ➜  kubectl describe no controlplane | grep -i cidr
PodCIDR:                      172.17.0.0/24
PodCIDRs:                     172.17.0.0/24
```

- `service-cluster-ip-range` 확인
```bash
> controlplane ~ ➜  k describe po kube-apiserver-controlplane -n kube-system
...
      --service-cluster-ip-range=172.20.0.0/16
...
```

- 클러스터 내 `kube-proxy` 개수 확인
```bash
> controlplane ~ ➜  k get po -n kube-system
...
kube-proxy-mfzqh                           1/1     Running   0          80m
kube-proxy-mhpqv                           1/1     Running   0          81m
...
```

- 현재 배포된 `kube-proxy`의 유형 확인
	- firewalld? iptables, userspace, ipvs
```bash
# kubectl 활용 확인 방법
controlplane ~ ➜  k logs kube-proxy-mhpqv -n kube-system
I0718 07:12:29.821660       1 server_linux.go:63] "Using iptables proxy"
...

# kube-proxy log 파일 확인 방법 (경로는 시스템에 따라 차이 존재)
controlplane ~ ✖ cat /var/log/pods/kube-system_kube-proxy-mhpqv_dedbff4c-5644-4bdb-ad72-5cce1c71fd61/kube-proxy/0.log

2025-07-18T07:12:29.821930865Z stderr F I0718 07:12:29.821660       1 server_linux.go:63] "Using iptables proxy"
...
```

- `kube-proxy`가 클러스터 내 모든 노드에 배포되는 것을 보장하는 방법
	- kube-proxy는 `DadmonSet`을 통해 배포된다. 따라서, 모드 노드에 `kube-proxy` 파드가 1개씩 배포된다.
```bash
controlplane ~ ➜  k describe -n kube-system po kube-proxy-mhpqv
...
Controlled By:  DaemonSet/kube-proxy
...
```